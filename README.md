# SOADML
Projet Stochastic Optimization and Automatic Differentiation for Machine Learning (ENSAE)


Le but de ce projet est de décrire et analyser différents types d’algorithmes pour résoudre le problème d'optimisation introduit par les machines à vecteurs de support (SVM).

Les algorithmes étudiés sont les suivants : 
  - Pegasos 
  - Stochastic Gradient Descent (SGD)
  - Pegasos Mini-Batch
  - Pegasos Kernel
  - Stochastic Dual Coordinate Ascent (SDCA)
  
Nous avons étudié la convergence de ces algorithmes sur plusieurs jeux de données (données linéaires séparables, données non linéaires séparables, données paraboliques et données réelles).

Dans le répertoire, vous trouverez le code en python et le rapport du projet.




